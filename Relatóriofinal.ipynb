{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141d1519-5c0b-4d32-b94b-7219aa43c7a0",
   "metadata": {},
   "source": [
    "# Relatório Final do Projeto de Programacao em Python\n",
    "\n",
    "\n",
    "\n",
    "## Basic Information\n",
    "\n",
    "- **Título**: Análise de Dados do Projeto em Python\n",
    "\n",
    "  \n",
    "- **Nome**: Emmanoel Cardoso  \n",
    "- **Número do Aluno**: 53570\n",
    "- **GitHub User**:emmanoelcardoos\n",
    "\n",
    "  \n",
    "- **Nome**: Diogo Ferreira\n",
    "- **Número do Aluno**: 55060\n",
    "- **GitHub User**:diogo1lf\n",
    "\n",
    "  \n",
    "- **Nome**: Kevin Llulluna \n",
    "- **Número do Aluno**: 53564\n",
    "- **GitHub User**: leobermudez10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aefe7e1-234e-4442-a988-d506f23a8698",
   "metadata": {},
   "source": [
    "## Contribution\n",
    "\n",
    "### Diogo Ferreira\n",
    "- **Responsabilidades**:\n",
    "  - Análise de Sentimento: Contar o número de tweets por sentimento (positivo, negativo, neutro).\n",
    "  - Análise de Sentimento: Calcular a percentagem de cada tipo de sentimento para todas as companhias aéreas.\n",
    "  - Análise de Sentimento: Identificar a companhia aérea com o maior número de tweets positivos.\n",
    "  - Análise de Sentimento: Analisar o número médio de retweets por tipo de sentimento.\n",
    "- **Esforço (horas)**: 2 horas.\n",
    "- **Descrição detalhada**: A ser preenchida após a realização das tarefas.\n",
    "\n",
    "### Kevin Llulluna\n",
    "- **Responsabilidades**:\n",
    "  - Análise de Companhias Aéreas: Listar todas as companhias aéreas mencionadas no dataset.\n",
    "  - Análise de Companhias Aéreas: Identificar a companhia com mais tweets negativos.\n",
    "  - Análise de Companhias Aéreas: Calcular o número total de tweets por companhia.\n",
    "  - Análise de Companhias Aéreas: Filtrar os tweets de uma companhia específica e mostrar seus detalhes.\n",
    "- **Esforço (horas)**: 2 horas.\n",
    "- **Descrição detalhada**: A ser preenchida após a realização das tarefas.\n",
    "\n",
    "### Emmanoel Cardoso\n",
    "- **Responsabilidades**:\n",
    "  - Processamento Temporal: Identificar o dia com maior número de tweets.\n",
    "  - Processamento Temporal: Contar quantos tweets foram feitos num determinado mês ou ano.\n",
    "  - Leitura de Dados: Implementar uma função para ler o ficheiro CSV e armazenar os dados numa estrutura apropriada.\n",
    "- **Esforço (horas)**: 2 horas.\n",
    "- **Descrição detalhada**: Trabalhou na construção das funções para ler os dados do arquivo csv e processamento temporal. Trabalhou tambem na criação deste relatório além da criação do pacote e repositório.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a47ef3-640c-4856-b262-7685f5296e73",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Este projeto de programação é uma atividade realizada por Emmanoel Cardoso, Kevin Llulluna e Diogo Ferreira, que tem como objetivo reforçar e aplicar os conceitos aprendidos durante a Unidade Curricular. O principal propósito foi desenvolver um package em Python capaz de realizar a leitura, processamento e análise de um dataset contendo tweets sobre companhias aéreas dos Estados Unidos. O dataset, fornecido pelo docente da cadeira e denominado Twitter US Airline Sentiment, apresenta informações sobre os sentimentos expressos em tweets relacionados às companhias aéreas.\n",
    "\n",
    "A solução que encontramos foi filtrar os tweets de avaliações do dataset, com o objetivo de ajudar as companhias aéreas estadunidenses a melhorar seus serviços com base nas opiniões indiretas de seus clientes.\n",
    "\n",
    "Com este projeto, esperamos que os dados do dataset sejam processados para permitir:\n",
    "\n",
    "- Análise de sentimentos dos passageiros.\n",
    "- Identificação das companhias aéreas mais comentadas.\n",
    "- Processamento temporal, que poderá ajudar as companhias a identificar avaliações específicas, especialmente durante períodos de alta # demanda, como feriados e festividades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f38ce5-026d-4d55-8de0-961fe7e5d68e",
   "metadata": {},
   "source": [
    "## Data Structure\n",
    "\n",
    "- **Pandas DataFrame**: Foi escolhido devido a sua forma otimizada para armazenar e manipular dados tabulares. Foi utilizado em Funções que manipulam grandes volumes de dados tabulares, como \"**carregar_dados**\" e \"**dia_com_mais_tweets**\". Tambem foi usado para ler o dataset devido a sua eficiencia em ler arquivos scv, foi usado para converter a coluna \"**tweet_created**\" para \"**datetime**\" de forma a melhor compreensao.\n",
    "   \n",
    "- **Lista de Dicionários**: devido a facilidade de se usar esse tipo de estruturas, a lista de dicionarios tornou-se util para trabalharmos com estruturas de dados não tabulados além de que os dados do arquivo csv foram lidos diretamente no formato de um dicionário.\n",
    "   \n",
    "- **Counter**: usamos para funcoes que exigiam contagens como \"**contador_sentiment**\" e \"**porcentage_sentimento**\". A principal justificativa é a sua forma simples de ser trabalhada.\n",
    "\n",
    "- **DefaultDict**: neste projeto foi usada para armazenar os sentimentos de cada companhia aérea \n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae52a6-48cb-46b4-80e1-d8e350701004",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "A função principal para carregar os dados do dataset em memória é a carregar_dados. Essa função foi desenvolvida utilizando a biblioteca Pandas, uma biblioteca conhecida por sua ajudar na manipulação de dados tabulares. O dataset inicial é fornecido no formato CSV e contém informações relevantes como texto de tweets, datas de publicação, entre outras colunas que foram fundamentais para o desenvolvimento do projeto. \n",
    "\n",
    "Usamos a funcao **carregar_dados** para tres principais tarefas:\n",
    "\n",
    "- 1: **Carregamento do Arquivo CSV**: Usa a função pd.read_csv() para importar o dataset como um DataFrame, facilitando sua manipulação e análise.\n",
    "- 2: **Conversão de Datas**: Transforma a coluna tweet_created para o formato datetime com pd.to_datetime(), essencial para análises temporais.\n",
    "- 3: **Tratamento de Erros**: Lida com erros como arquivos não encontrados (FileNotFoundError), problemas no formato (ParserError) e outros imprevistos, garantindo eficiencia no processo.\n",
    "\n",
    "As dificudades encontradas na leitura de dados foram exatamente as diferencas como o arquivo foi codificado (principalemnte quando haviam elementos com caracteres especiais) o qual foi ajusatdo usando o parametro enconding; a incosistencia ou datas mal formadas e principalemnte o tamaho do dataset que exigiu muita memoria para ler o arquivo. Neste ultimo, a solucao encontrada para que nao houvesse sobrecarga durante o processo foi a autilizacao de uma funcao chamada chunksize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01daca6-5a3d-4877-9e4d-d5cdddd18105",
   "metadata": {},
   "source": [
    "## Processamento e análise de dados\n",
    "\n",
    "O propósito principal do processamento e análise é transformar os dados brutos do dataset em informações relevantes, identificando padrões, tendências e insights que possam auxiliar no entendimento do sentimento dos usuários em relação às companhias aéreas nos Estados Unidos.\n",
    "As funções utilizadas no projeto realizam etapas como filtragem, contagem de sentimentos, análise temporal dos dadose analise das cias aereas.\n",
    "\n",
    "- 1: **carregar_dados()**\n",
    "    - Propósito: Carregar o dataset em formato CSV, converter a coluna de datas para o formato datetime e tratar erros no carregamento.\n",
    "    - Análise Possível: Garantir que os dados estejam no formato correto para análises futuras, como contagem de tweets em intervalos   específicos e extração de padrões temporais.\n",
    "      \n",
    "     \n",
    "- 2: **dia_com_mais_tweets()**\n",
    "    - Propósito: Identificar o dia com o maior número de tweets no dataset.\n",
    "    - Insight Extraído: Por meio dessa análise, é possível entender se os usuários tendem a mencionar companhias aéreas em determinados períodos ou em resposta a eventos específicos.\n",
    "      \n",
    "    \n",
    "- 3: **contar_tweets_por_periodo(ano, mes)**\n",
    "    - Propósito: Contar quantos tweets foram publicados em um determinado período (meses ou anos) para realizar análises temporais.\n",
    "    - Insight Extraído: Permite identificar os períodos com maior quantidade de menções, facilitando o estudo de padrões sazonais ou eventos específicos.\n",
    "      \n",
    "   \n",
    "- 4: **filtro_tweet(data, companhia)**:\n",
    "    - Propósito: Filtrar os dados para considerar apenas os tweets relacionados a uma companhia aérea específica.\n",
    "    - Insight Extraído: Com essa filtragem, é possível analisar as percepções de usuários para cada companhia individualmente.\n",
    "      \n",
    "   \n",
    "- 5: **porcentage_sentimento(data)**:\n",
    "    - Propósito: Calcular a porcentagem de sentimentos (positivo, negativo, neutro) associados a cada companhia aérea no dataset.\n",
    "    - Insight Extraído: É possível identificar quais companhias aéreas possuem uma reputação positiva ou negativa com base nos sentimentos predominantes nos tweets.\n",
    "      \n",
    "\n",
    "- 6: **positive_tweet(data)**:\n",
    "\n",
    "    - Propósito: Determinar qual companhia aérea teve mais menções positivas no conjunto de dados.\n",
    "    - Insight Extraído: Isso pode indicar a companhia mais bem avaliada pelos usuários no período analisado, oferecendo informações úteis para estratégias de imagem e marketing.\n",
    "      \n",
    "\n",
    "- 7: **contador_sentiment(data)**:\n",
    "\n",
    "    - Propósito: Contar o número total de sentimentos no conjunto de dados.\n",
    "    - Insight Extraído: Auxilia a identificar a distribuição geral dos sentimentos no dataset, oferecendo uma visão panorâmica sobre a percepção dos usuários em relação às companhias aéreas.\n",
    "\n",
    "- 8: **realizar_login(user, password)**  \n",
    "  - Propósito: Simular o processo de login verificando as credenciais de usuário e senha.  \n",
    "  - Insight Extraído:Registra no log todas as tentativas de login (bem-sucedidas ou falhas), facilitando o monitoramento e a análise de atividades no sistema.\n",
    "\n",
    "\n",
    "\n",
    "- 9: **companhia_com_mais_tweets_negativos(tweets)**  \n",
    "  - Propósito: Encontrar a companhia aérea mencionada com mais frequência em tweets negativos.  \n",
    "  - Insight Extraído: Identificar qual companhia aérea está enfrentando maior percepção negativa, possibilitando ações estratégicas para melhorar sua imagem.\n",
    "\n",
    "\n",
    "- 10: **filtrar_tweets_por_companhia(tweets, companhia)**  \n",
    "  - Propósito: Filtrar os tweets relevantes de uma companhia aérea específica.  \n",
    "  - Insight Extraído: Permite análises direcionadas, comparando sentimentos e tendências específicas por companhia.\n",
    "\n",
    "\n",
    "- 11: **listar_companhias(tweets)**  \n",
    "  - Propósito: Listar todas as companhias únicas mencionadas no conjunto de dados de tweets.  \n",
    "  - Insight Extraído: Fornece uma visão geral das companhias aéreas abordadas nos dados, possibilitando análises comparativas.\n",
    "\n",
    "\n",
    "- 12: **total_tweets_por_companhia(tweets)**  \n",
    "  - Propósito: Contar o número total de tweets associados a cada companhia aérea no conjunto de dados.  \n",
    "  - Insight Extraído: Permite identificar as companhias mais mencionadas no conjunto de dados, oferecendo informações úteis sobre o engajamento dos usuários.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Exemplos de Uso:\n",
    "```\n",
    "- 1: **carregar_dados()**\n",
    "\n",
    "from processo_temporal import carregar_dados\n",
    "dados = carregar_dados()\n",
    "if dados is not None:\n",
    "    print(dados.head())  # Visualiza os dados carregados\n",
    "else:\n",
    "    print(\"Erro ao carregar os dados!\")\n",
    "\n",
    "\n",
    "- 2: **dia_com_mais_tweets()**\n",
    "  \n",
    "from processo_temporal import dia_com_mais_tweets\n",
    "dados = carregar_dados()\n",
    "dia_mais_tweets, total_tweets = dia_com_mais_tweets(dados)\n",
    "print(f\"Dia com mais tweets: {dia_mais_tweets}, com {total_tweets} tweets.\")\n",
    "\n",
    "- 3: **contar_tweets_por_periodo(ano, mes)**\n",
    "\n",
    "from processo_temporal import contar_tweets_por_periodo\n",
    "dados = carregar_dados()\n",
    "total_ano = contar_tweets_por_periodo(dados, ano=2015)\n",
    "print(f\"Total de tweets no ano de 2015: {total_ano}\")\n",
    "total_mes = contar_tweets_por_periodo(dados, ano=2015, mes=2)\n",
    "print(f\"Total de tweets em Fevereiro de 2015: {total_mes}\")\n",
    "\n",
    "- 4: **filtro_tweet(data, companhia)**:\n",
    "\n",
    "from analise_sentimento import filtro_tweet\n",
    "tweets_delta = filtro_tweet(dados, companhia=\"Delta\")\n",
    "print(f\"Total de tweets da companhia Delta: {len(tweets_delta)}\")\n",
    "print(\"Exemplo de tweets:\", tweets_delta[:3])\n",
    "\n",
    "- 5: **porcentage_sentimento(data)**:\n",
    "\n",
    "from analise_sentimento import porcentage_sentimento\n",
    "percentuais = porcentage_sentimento(dados)\n",
    "for companhia, sentimento in percentuais.items():\n",
    "    print(f\"Companhia: {companhia}, Porcentagem: {sentimento}\")\n",
    "percentuais = porcentage_sentimento(dados)\n",
    "for companhia, sentimento in percentuais.items():\n",
    "    print(f\"Companhia: {companhia}, Porcentagem: {sentimento}\")\n",
    "\n",
    "- 6: **positive_tweet(data)**:\n",
    "\n",
    "from analise_sentimento import positive_tweet\n",
    "companhia_mais_positiva = positive_tweet(dados)\n",
    "print(f\"Companhia com maior número de tweets positivos: {companhia_mais_positiva}\")\n",
    "\n",
    "- 7: **Realizar login\n",
    "\n",
    "from analise_login import realizar_login\n",
    "login_valido = realizar_login(\"main\", \"123456\")\n",
    "if login_valido:\n",
    "    print(\"Login bem-sucedido!\")\n",
    "else:\n",
    "    print(\"Falha no login.\")\n",
    "\n",
    "login_invalido = realizar_login(\"user\", \"senha\")\n",
    "if login_invalido:\n",
    "    print(\"Login bem-sucedido!\")\n",
    "else:\n",
    "    print(\"Falha no login.\")\n",
    "\n",
    "\n",
    "- 8: **Companhia com mais tweets negativos**\n",
    "\n",
    "from analise_sentimento import companhia_com_mais_tweets_negativos\n",
    "tweets_exemplo = [\n",
    "    {\"airline\": \"Airline A\", \"airline_sentiment\": \"positive\"},\n",
    "    {\"airline\": \"Airline B\", \"airline_sentiment\": \"negative\"},\n",
    "    {\"airline\": \"Airline A\", \"airline_sentiment\": \"negative\"},\n",
    "    {\"airline\": \"Airline C\", \"airline_sentiment\": \"neutral\"},\n",
    "    {\"airline\": \"Airline B\", \"airline_sentiment\": \"negative\"}\n",
    "]\n",
    "companhia_mais_negativa = companhia_com_mais_tweets_negativos(tweets_exemplo)\n",
    "print(f\"A companhia com mais tweets negativos é: {companhia_mais_negativa}\")\n",
    "\n",
    "\n",
    "- 9 **Filtrar tweets por companhia**\n",
    "\n",
    "from analise_sentimento import filtrar_tweets_por_companhia\n",
    "tweets_da_airline_a = filtrar_tweets_por_companhia(tweets_exemplo, \"Airline A\")\n",
    "print(f\"Total de tweets da Airline A: {len(tweets_da_airline_a)}\")\n",
    "print(\"Exemplo de tweets:\", tweets_da_airline_a[:3])\n",
    "\n",
    "\n",
    "- 10: **Listar companhias únicas**\n",
    "\n",
    "from analise_sentimento import listar_companhias\n",
    "companhias = listar_companhias(tweets_exemplo)\n",
    "print(\"Companhias únicas nos tweets:\", companhias)\n",
    "\n",
    "\n",
    "- 11: **Total de tweets por companhia**\n",
    "\n",
    "from analise_sentimento import total_tweets_por_companhia\n",
    "total_companhias = total_tweets_por_companhia(tweets_exemplo)\n",
    "for companhia, total in total_companhias.items():\n",
    "    print(f\"Companhia: {companhia}, Total de tweets: {total}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4e3e5-9f6f-44bd-b047-78ef44c1207b",
   "metadata": {},
   "source": [
    "## Logs\n",
    "\n",
    "Explicação sobre o Conteúdo e Utilização do Ficheiro de Logs\n",
    "\n",
    "O código utiliza um **mecanismo de logging** (registros de execução) para capturar eventos importantes e possíveis erros durante a execução do programa. O arquivo de log é configurado com o nome **`excecoes_log.py`**. Vamos detalhar seu conteúdo e seu propósito:\n",
    "\n",
    "---\n",
    "\n",
    "## Configuração do Logger\n",
    "\n",
    "O logger é configurado com as seguintes características:\n",
    "\n",
    "```python\n",
    "logging.basicConfig(\n",
    "    filename='excecoes_log.py',\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3d216-222f-453b-8fa7-2ca558c3f7e9",
   "metadata": {},
   "source": [
    "## Asserts e Exceções\n",
    "\n",
    "\n",
    "- **Uso dos Asserts e Exceções no código:**\n",
    "\n",
    "No código do `main.py`, as Exceções e Asserts foram implementados para:\n",
    "\n",
    "1. **Evitar erros que podem interromper o programa sem aviso.**  \n",
    "2. **Garantir que os dados e condições essenciais sejam válidos antes de prosseguir com as análises.**  \n",
    "\n",
    "- **Exceções**  \n",
    "Capturam falhas, como erros ao tentar carregar arquivos ou se os dados estiverem inválidos.\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "```python\n",
    "try:\n",
    "    dados = carregar_dados()\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo não encontrado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro desconhecido: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc14ca-29a5-4cd7-b34b-f9d6c60344b5",
   "metadata": {},
   "source": [
    "## Declaração de Honra e Integridade Académica\n",
    "\n",
    "Eu, Emmanoel Cardoso, estudante com o número de inscrição 53570 de/o 1º Ciclo em Inteligência Artificial\n",
    "e Ciência de Dados da Universidade da Beira Interior, declaro ter desenvolvido o presente\n",
    "trabalho e elaborado o presente texto em total consonância com o Código de Integridade\n",
    "da Universidade da Beira Interior. Mais concretamente afirmo não ter incorrido em\n",
    "qualquer das variedades de Fraude Académica, e que aqui declaro conhecer, que em\n",
    "particular atendi à exigida referenciação de frases, extratos, imagens e outras formas de\n",
    "trabalho intelectual, e assumindo assim na íntegra as responsabilidades da autoria.\n",
    "Universidade da Beira Interior, Covilhã\n",
    "18/12/2024\n",
    "\n",
    "Eu, Kevin LLulluna, estudante com o número de inscrição 53564 de/o 1º Ciclo em Inteligência Artificial\n",
    "e Ciência de Dados da Universidade da Beira Interior, declaro ter desenvolvido o presente\n",
    "trabalho e elaborado o presente texto em total consonância com o Código de Integridade\n",
    "da Universidade da Beira Interior. Mais concretamente afirmo não ter incorrido em\n",
    "qualquer das variedades de Fraude Académica, e que aqui declaro conhecer, que em\n",
    "particular atendi à exigida referenciação de frases, extratos, imagens e outras formas de\n",
    "trabalho intelectual, e assumindo assim na íntegra as responsabilidades da autoria.\n",
    "Universidade da Beira Interior, Covilhã\n",
    "18/12/2024\n",
    "\n",
    "Eu, Diogo Ferreira, estudante com o número de inscrição 55060 de/o 1º Ciclo em Inteligência Artificial\n",
    "e Ciência de Dados da Universidade da Beira Interior, declaro ter desenvolvido o presente\n",
    "trabalho e elaborado o presente texto em total consonância com o Código de Integridade\n",
    "da Universidade da Beira Interior. Mais concretamente afirmo não ter incorrido em\n",
    "qualquer das variedades de Fraude Académica, e que aqui declaro conhecer, que em\n",
    "particular atendi à exigida referenciação de frases, extratos, imagens e outras formas de\n",
    "trabalho intelectual, e assumindo assim na íntegra as responsabilidades da autoria.\n",
    "Universidade da Beira Interior, Covilhã\n",
    "18/12/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa21a3-72e3-46a4-adee-8db8f97aaed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
